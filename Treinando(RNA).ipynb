{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19e79754",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "üìò Etapas do Projeto:\n",
    "\n",
    "1. Carregamento do dataset de c√¢ncer de mama (UCI)\n",
    "2. Pr√©-processamento dos dados (normaliza√ß√£o e codifica√ß√£o)\n",
    "3. Cria√ß√£o de modelos:\n",
    "   - MLP (Rede Neural Multicamadas)\n",
    "   - Random Forest\n",
    "   - SVM\n",
    "4. Avalia√ß√£o de desempenho com matriz de confus√£o e relat√≥rio de classifica√ß√£o\n",
    "5. Interpreta√ß√£o com SHAP (valores de import√¢ncia por atributo)\n",
    "6. Interpreta√ß√£o com LIME (explica√ß√£o local por inst√¢ncia)\n",
    "7. Exporta√ß√£o do relat√≥rio LIME em HTML\n",
    "\n",
    "Este c√≥digo pode ser adaptado para outros datasets com ajustes m√≠nimos.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21a163a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shap'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msvm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SVC\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mshap\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlime\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlime\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlime_tabular\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LimeTabularExplainer\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'shap'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import shap\n",
    "import lime\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "# 1. Carregar dataset\n",
    "def load_data():\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\"\n",
    "    columns = ['ID', 'Diagnosis'] + [f'Feature_{i}' for i in range(1, 31)]\n",
    "    df = pd.read_csv(url, header=None, names=columns)\n",
    "    df.drop(columns=['ID'], inplace=True)  # Remover ID\n",
    "    return df\n",
    "\n",
    "df = load_data()\n",
    "print(\"\\nüîç Visualiza√ß√£o inicial do dataset carregado:\")\n",
    "print(df.head())\n",
    "\n",
    "# 2. Pr√©-processamento\n",
    "def preprocess_data(df):\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['Diagnosis'] = label_encoder.fit_transform(df['Diagnosis'])  # M -> 1, B -> 0\n",
    "    X = df.drop(columns=['Diagnosis'])\n",
    "    y = df['Diagnosis']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) #Divis√£o entre treino e teste (80% treino, 20% teste)\n",
    "    scaler = StandardScaler() #--\n",
    "    X_train = scaler.fit_transform(X_train)# transforma os dados para que tenham m√©dia 0 e desvio padr√£o 1\n",
    "    X_test = scaler.transform(X_test)#--\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = preprocess_data(df)\n",
    "print(\"\\n‚úÖ Dados normalizados e divididos em treino e teste.\")\n",
    "\n",
    "# 3. Modelos\n",
    "def create_mlp():\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(X_train.shape[1],)), #64 neur√¥nios com ReLU, recebe as 30 features do dataset.\n",
    "        Dense(32, activation='relu'),#desativa aleatoriamente 30% dos neur√¥nios a cada passo para evitar overfitting\n",
    "        Dense(1, activation='sigmoid')#1 neur√¥nio com fun√ß√£o sigmoide\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy']) \n",
    "    return model\n",
    "\n",
    "print(\"\\n‚öôÔ∏è  Iniciando o treinamento da Rede Neural (MLP)...\")\n",
    "mlp_model = create_mlp()\n",
    "history = mlp_model.fit(X_train, y_train, epochs=20, validation_split=0.2, batch_size=16, verbose=1)\n",
    "#epochs=20: passa pelos dados 20 vezes.\n",
    "#validation_split=0.2: separa 20% do treino para valida√ß√£o interna.\n",
    "#batch_size=16: treina com 16 amostras por vez (mais est√°vel que 1).\n",
    "\n",
    "# Gr√°fico de Acur√°cia do MLP\n",
    "print(\"\\nüìà Gr√°fico de evolu√ß√£o da acur√°cia durante o treinamento da MLP:\")\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['accuracy'], label='Acur√°cia Treino', marker='o')\n",
    "plt.plot(history.history['val_accuracy'], label='Acur√°cia Valida√ß√£o', marker='s')\n",
    "plt.title('Evolu√ß√£o da Acur√°cia - MLP', fontsize=14)\n",
    "plt.xlabel('√âpocas')\n",
    "plt.ylabel('Acur√°cia')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Outros Modelos\n",
    "print(\"\\n‚öôÔ∏è  Treinando modelos de compara√ß√£o (Random Forest e SVM)...\")\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "svm_model = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# 5. Avalia√ß√£o\n",
    "def evaluate_model(model, X_test, y_test, model_name=\"Model\"):\n",
    "    print(f\"\\nüìä Avalia√ß√£o do modelo: {model_name}\")\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(int) if isinstance(model, tf.keras.Model) else model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"\\n{model_name} Accuracy: {acc:.4f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Purples', cbar=False, xticklabels=['Benigno', 'Maligno'], yticklabels=['Benigno', 'Maligno'])\n",
    "    plt.title(f'Matriz de Confus√£o - {model_name}')\n",
    "    plt.xlabel('Previsto')\n",
    "    plt.ylabel('Real')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "evaluate_model(mlp_model, X_test, y_test, \"MLP\")\n",
    "evaluate_model(rf_model, X_test, y_test, \"Random Forest\")\n",
    "evaluate_model(svm_model, X_test, y_test, \"SVM\")\n",
    "\n",
    "# 6. Interpreta√ß√£o com SHAP\n",
    "print(\"\\nüß† An√°lise com SHAP: import√¢ncia das features no modelo Random Forest\")\n",
    "explainer = shap.Explainer(rf_model, X_train)\n",
    "shap_values = explainer(X_test[:50])\n",
    "shap.summary_plot(shap_values, X_test[:50])\n",
    "\n",
    "# 7. Interpreta√ß√£o com LIME\n",
    "print(\"\\nüß™ An√°lise local com LIME: explica√ß√£o de uma predi√ß√£o espec√≠fica\")\n",
    "explainer = LimeTabularExplainer(X_train, mode=\"classification\", training_labels=y_train, feature_names=df.columns[1:])\n",
    "exp = explainer.explain_instance(X_test[0], rf_model.predict_proba, num_features=5)\n",
    "\n",
    "# Salvar explica√ß√£o LIME como HTML\n",
    "exp.save_to_file('explicacao_lime.html')\n",
    "print(\"‚úÖ Explica√ß√£o LIME salva como 'explicacao_lime.html'. Abra o arquivo para ver a an√°lise visual.\")\n"
   ]

